{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM0JCUSBDbAfRXj2usB+vGq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Ex. 1. Pe baza definiţiei unui model Markov ascuns, demonstraţi formula recurenţei pentru variabila forward de la pagina 23 a cursului 4. Încărcaţi argumentul fie în Markdown/Latex, fie ca foto la foia de lucru."],"metadata":{"id":"SbSj1scB0pei"}},{"cell_type":"markdown","source":["\n","Pentru a demonstra formula recurenței pentru variabila forward, să ne reamintim că variabila forward $ \\alpha_t(i) $ reprezintă probabilitatea de a fi în starea ascunsă **i** la momentul **t**, având în vedere observațiile $ O_1, O_2, \\ldots, O_t $. Adică:\n","\n","$$\n","\\alpha_t(i) = P(O_1, O_2, \\ldots, O_t, X_t = i)\n","$$\n","\n","Formula recurenței pentru variabila forward este:\n","\n","$$\n","\\alpha_{t+1}(j) = \\left( \\sum_{i=1}^N \\alpha_t(i) \\cdot a_{ij} \\right) \\cdot b_j(O_{t+1})\n","$$\n","\n","unde:\n","- **$a_{ij}$** este probabilitatea de tranziție de la starea **$i$** la starea **$j$**,\n","- **$b_j(O_{t+1})$** este probabilitatea ca starea **$j$** să genereze observația *$O_{t+1}$*.\n","\n","### Demonstrația formulei recurenței forward\n","\n","1. **Definirea probabilității forward**: La momentul $ t+1 $, probabilitatea de a observa secvența $ O_1, O_2, \\ldots, O_{t+1} $ și de a fi în starea ascunsă $ j $ este dată de variabila forward $ \\alpha_{t+1}(j) $.\n","\n","2. **Determinarea probabilităților pentru toate tranzițiile posibile**: Pentru a ajunge în starea $ j $ la momentul $ t+1 $, sistemul poate trece din oricare dintre stările $ i = 1, 2, \\ldots, N $ la momentul $ t $ în starea $ j $ la momentul $ t+1 $. Astfel, trebuie să adunăm contribuțiile tuturor stărilor anterioare.\n","\n","3. **Calculul probabilității pentru fiecare tranziție**:\n","   - Probabilitatea de a fi în starea $ i $ la momentul $ t $ și de a observa secvența $ O_1, O_2, \\ldots, O_t $ este $ \\alpha_t(i) $.\n","   - Probabilitatea de a face tranziția de la starea $ i $ la starea $ j $ este $ a_{ij} $.\n","   - Probabilitatea ca starea $ j $ să genereze observația $ O_{t+1} $ este $ b_j(O_{t+1}) $.\n","\n","4. **Concluzie**: Prin urmare, formula recurenței forward este:\n","\n","$$\n","\\alpha_{t+1}(j) = \\left( \\sum_{i=1}^N \\alpha_t(i) \\cdot a_{ij} \\right) \\cdot b_j(O_{t+1})\n","$$\n","\n","Această formulă este obținută prin adunarea tuturor probabilităților de a ajunge în starea $ j $ la momentul $ t+1 $ din toate stările posibile la momentul $ t $, multiplicând cu probabilitatea observației corespunzătoare.\n"],"metadata":{"id":"SNRhHAa_0tYG"}},{"cell_type":"markdown","source":["### Ex. 2. Reluaţi exerciţiul de la laborator, de data aceasta implementând direct alogritmul Viterbi descris în cursul 4. Mai jos redăm enunţul acestuia:\n","Un profesor dă teste care pot fi dificile, medii sau uşoare. Probabilitatea dificultăţii primului test este aceeaşi. Dacă, la un moment dat, dă un test dificil, următorul test poate fi doar mediu sau uşor, cu aceeaşi probabilitate. Însă dacă dă un test mediu sau uşor, atunci următorul test va fi dificil cu probabilitate 0.5, sau mediu sau uşor cu aceeaşi probabilitate, 0.25.\n","\n","\n","Nota unui student la test, FB, B, S sau NS depinde de dificultatea testului. Astfel, probabilităţile condiţionate ale notei\n","obţinute, dată fiind dificultatea testului, sunt:\n","  - test dificil: [0.1, 0.2, 0.4, 0.3];\n","  - test mediu: [0.15, 0.25, 0.5, 0.1];\n","  - test uşor: [0.2, 0.3, 0.4, 0.1].\n","  \n","Să presupunem că aţi observat următoarea secvenţă de note: FB, FB, S, B, B, S, B, B, NS, B, B, S. Determinaţi cea mai\n","probabilă secvenţă de dificultăţi pentru testele corespunzaătoare şi probabilitatea acesteia."],"metadata":{"id":"bwm92kgE6iRL"}},{"cell_type":"markdown","source":["Vom implementa algoritmul Viterbi, care este folosit pentru a determina cea mai probabilă secvență de stări ascunse date o secvență de observații.\n","\n","### Pasul 1: Definirea modelului\n","\n","1. **Stările posibile (dificultățile testelor)**:\n","   - Dificil (D)\n","   - Mediu (M)\n","   - Ușor (U)\n","\n","2. **Observațiile posibile (notele obținute)**:\n","   - FB (Foarte Bine)\n","   - B (Bine)\n","   - S (Satisfăcător)\n","   - NS (Nesatisfăcător)\n","\n","3. **Probabilitățile de tranziție**:\n","   - $ P(D \\to D) = 0 $\n","   - $ P(D \\to M) = 0.5 $\n","   - $ P(D \\to U) = 0.5 $\n","   - $ P(M \\to D) = 0.5 $\n","   - $ P(M \\to M) = 0.25 $\n","   - $ P(M \\to U) = 0.25 $\n","   - $ P(U \\to D) = 0.5 $\n","   - $ P(U \\to M) = 0.25 $\n","   - $ P(U \\to U) = 0.25 $\n","\n","4. **Probabilitățile emiterii**:\n","   - Dificil: $ [0.1, 0.2, 0.4, 0.3] $ (probabilitățile pentru FB, B, S, NS)\n","   - Mediu: $ [0.15, 0.25, 0.5, 0.1] $\n","   - Ușor: $ [0.2, 0.3, 0.4, 0.1] $\n","\n","5. **Secvența de observații**:\n","   - FB, FB, S, B, B, S, B, B, NS, B, B, S\n","\n","### Pasul 2: Implementarea algoritmului Viterbi\n","\n","Implementez o funcție Python pentru a implementa algoritmul Viterbi și pentru a calcula cea mai probabilă secvență de dificultăți pentru testele corespunzătoare."],"metadata":{"id":"gNnDHdqb7n2y"}},{"cell_type":"code","source":["import numpy as np\n","\n","# Definirea stărilor și observațiilor\n","states = ['D', 'M', 'U']  # Stările posibile: Dificil, Mediu, Ușor\n","observations = ['FB', 'B', 'S', 'NS']  # Observațiile: Foarte Bine, Bine, Satisfăcător, Nesatisfăcător\n","\n","# Probabilitățile de tranziție între stări conform enunțului\n","transition_probs = {\n","    'D': {'D': 0, 'M': 0.5, 'U': 0.5},\n","    'M': {'D': 0.5, 'M': 0.25, 'U': 0.25},\n","    'U': {'D': 0.5, 'M': 0.25, 'U': 0.25},\n","}\n","\n","# Probabilitățile de emisie pentru fiecare stare\n","emission_probs = {\n","    'D': {'FB': 0.1, 'B': 0.2, 'S': 0.4, 'NS': 0.3},  # Probabilitățile pentru fiecare observație în stare Dificil\n","    'M': {'FB': 0.15, 'B': 0.25, 'S': 0.5, 'NS': 0.1},  # Probabilitățile pentru fiecare observație în stare Mediu\n","    'U': {'FB': 0.2, 'B': 0.3, 'S': 0.4, 'NS': 0.1},    # Probabilitățile pentru fiecare observație în stare Ușor\n","}\n","\n","# Observațiile date de enunț\n","observed_sequence = ['FB', 'FB', 'S', 'B', 'B', 'S', 'B', 'B', 'NS', 'B', 'B', 'S']\n","\n","# Algoritmul Viterbi\n","def viterbi(observations, states, transition_probs, emission_probs):\n","    n_states = len(states)\n","    n_observations = len(observations)\n","\n","    # Inițializare: matricea Viterbi și backpointer-ul\n","    viterbi_matrix = np.zeros((n_states, n_observations))\n","    backpointer = np.zeros((n_states, n_observations), dtype=int)\n","\n","    # Probabilitatea inițială este egală pentru toate stările (1 / numărul de stări)\n","    initial_prob = 1 / n_states\n","    for s in range(n_states):\n","        viterbi_matrix[s, 0] = initial_prob * emission_probs[states[s]][observations[0]]\n","\n","    # Recursia Viterbi\n","    for t in range(1, n_observations):\n","        for s in range(n_states):\n","            max_prob = -1\n","            max_state = -1\n","            for s_prev in range(n_states):\n","                prob = (\n","                    viterbi_matrix[s_prev, t-1] *\n","                    transition_probs[states[s_prev]][states[s]] *\n","                    emission_probs[states[s]][observations[t]]\n","                )\n","                if prob > max_prob:\n","                    max_prob = prob\n","                    max_state = s_prev\n","            viterbi_matrix[s, t] = max_prob\n","            backpointer[s, t] = max_state\n","\n","    # Reconstruirea celei mai probabile secvențe folosind backpointer-ul\n","    best_path = []\n","    best_last_state = np.argmax(viterbi_matrix[:, n_observations - 1])\n","    best_path.append(states[best_last_state])\n","\n","    for t in range(n_observations - 1, 0, -1):\n","        best_last_state = backpointer[best_last_state, t]\n","        best_path.append(states[best_last_state])\n","\n","    best_path.reverse()\n","    return best_path, viterbi_matrix[:, -1].max()\n","\n","# Executăm algoritmul Viterbi pentru secvența observată\n","best_path, best_path_prob = viterbi(observed_sequence, states, transition_probs, emission_probs)\n","\n","# Afișarea rezultatelor\n","print(\"Cea mai probabilă secvență de dificultăți:\", best_path)\n","print(\"Probabilitatea secvenței:\", best_path_prob)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_kT6QWjG8F7t","executionInfo":{"status":"ok","timestamp":1730804146905,"user_tz":-120,"elapsed":290,"user":{"displayName":"Daria-Stefania Ilisei","userId":"11417503906145554138"}},"outputId":"102fec85-9e0c-478c-a3ef-4fa80f6135c9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Cea mai probabilă secvență de dificultăți: ['D', 'U', 'D', 'U', 'D', 'M', 'D', 'U', 'D', 'U', 'D', 'M']\n","Probabilitatea secvenței: 2.1093750000000005e-11\n"]}]}]}